{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation using VGGSegNet\n",
    "# VGG-16 Network based Encoder-Decoder FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import VGGSegnet\n",
    "import LoadBatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "input_height = 224\n",
    "input_width = 224\n",
    "\n",
    "train_images_path = \"data/images_prepped_train/\"\n",
    "train_segs_path = \"data/annotations_prepped_train/\"\n",
    "train_batch_size = 2\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "save_weights_path = './weights_'\n",
    "#load_weights = args.load_weights\n",
    "\n",
    "optimizer_name = 'adadelta'\n",
    "modelFN = VGGSegnet\n",
    "\n",
    "if validate:\n",
    "    val_images_path = \"data/images_prepped_test/\"\n",
    "    val_segs_path = \"data/annotations_prepped_test/\"\n",
    "    val_batch_size = 2\n",
    "\n",
    "m = modelFN(n_classes, input_height=input_height, input_width=input_width)\n",
    "m.compile(loss='categorical_crossentropy',\n",
    "          optimizer=optimizer_name,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "if len(load_weights) > 0:\n",
    "    m.load_weights(load_weights)\n",
    "\n",
    "\n",
    "print (\"Model output shape\",  m.output_shape)\n",
    "\n",
    "output_height = m.outputHeight\n",
    "output_width = m.outputWidth\n",
    "\n",
    "G = LoadBatches.imageSegmentationGenerator(\n",
    "    train_images_path, train_segs_path,  train_batch_size,  n_classes, input_height, input_width, output_height, output_width)\n",
    "\n",
    "\n",
    "if validate:\n",
    "    G2 = LoadBatches.imageSegmentationGenerator(\n",
    "        val_images_path, val_segs_path,  val_batch_size,  n_classes, input_height, input_width, output_height, output_width)\n",
    "\n",
    "if not validate:\n",
    "    for ep in range(epochs):\n",
    "        m.fit_generator(G, 512, epochs=1)\n",
    "        m.save_weights(save_weights_path + \".\" + str(ep))\n",
    "        m.save(save_weights_path + \".model.\" + str(ep))\n",
    "else:\n",
    "    for ep in range(epochs):\n",
    "        m.fit_generator(G, 512, validation_data=G2,\n",
    "                        validation_steps=200,  epochs=1)\n",
    "        m.save_weights(save_weights_path + \".\" + str(ep))\n",
    "        m.save(save_weights_path + \".model.\" + str(ep))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
