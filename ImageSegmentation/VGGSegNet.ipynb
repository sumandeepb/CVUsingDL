{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Segmentation using VGGSegNet\n",
    "# VGG-16 Network based Encoder-Decoder FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.utils import plot_model\n",
    "from VGGSegnet import VGGSegnet\n",
    "import LoadBatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data path\n",
    "train_images_path = \"data/images_prepped_train/\"\n",
    "train_segs_path = \"data/annotations_prepped_train/\"\n",
    "\n",
    "# parameters of dataset \n",
    "n_classes = 10\n",
    "input_height = 224\n",
    "input_width = 224\n",
    "\n",
    "# training hyper parameters\n",
    "train_batch_size = 2\n",
    "epochs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model and optimizer\n",
    "model = VGGSegnet(n_classes, input_height=input_height, input_width=input_width)\n",
    "\n",
    "optimizer_name = 'adadelta'\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=optimizer_name, metrics=['accuracy'])\n",
    "\n",
    "print (\"Model output shape\",  model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dimentions\n",
    "output_height = model.outputHeight\n",
    "output_width = model.outputWidth\n",
    "\n",
    "# load data into pre-batches\n",
    "G = LoadBatches.imageSegmentationGenerator(\n",
    "    train_images_path, train_segs_path,\n",
    "    train_batch_size,  n_classes,\n",
    "    input_height, input_width,\n",
    "    output_height, output_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model.fit_generator(G, 512, epochs=epochs)\n",
    "\n",
    "# save model & weights\n",
    "model.save_weights('vggsegnet_weights_test.h5')\n",
    "model.save('vggsegnet_model_test.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data path\n",
    "test_images=\"data/images_prepped_test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model and optimizer\n",
    "modelFN = VGGSegnet\n",
    "optimizer_name = 'adadelta'\n",
    "\n",
    "model = modelFN(n_classes, input_height=input_height, input_width=input_width)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=optimizer_name, metrics=['accuracy'])\n",
    "\n",
    "# load weights from file\n",
    "model.load_weights('weights/vggsegnet_weights.19.h5')\n",
    "\n",
    "print (\"Model output shape\",  model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "images = glob.glob(test_images + \"*.png\")\n",
    "images.sort()\n",
    "print (\"Test Set Size: \", len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output dimentions\n",
    "output_height = model.outputHeight\n",
    "output_width = model.outputWidth\n",
    "\n",
    "# set random colors for output\n",
    "colors = [(250, 206, 135), (0, 255, 255), (0, 255, 0), (64, 64, 64), (255, 255, 255),\n",
    "          (34, 139, 34), (0, 0, 0), (255, 0, 255), (0, 0, 255), (0, 0, 128)]\n",
    "\n",
    "# process image one by one\n",
    "for imgName in images:\n",
    "    X = LoadBatches.getImageArr(imgName, input_width, input_height)\n",
    "    \n",
    "    pr = model.predict(np.array([X]))[0]\n",
    "    pr = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)\n",
    "    \n",
    "    seg_img = np.zeros((output_height, output_width, 3))\n",
    "    for c in range(n_classes):\n",
    "        seg_img[:, :, 0] += ((pr[:, :] == c)*(colors[c][0])).astype('uint8')\n",
    "        seg_img[:, :, 1] += ((pr[:, :] == c)*(colors[c][1])).astype('uint8')\n",
    "        seg_img[:, :, 2] += ((pr[:, :] == c)*(colors[c][2])).astype('uint8')\n",
    "    \n",
    "    seg_img = cv2.resize(seg_img, (input_width, input_height))\n",
    "    \n",
    "    cv2.imwrite('data/prediction.png', seg_img)\n",
    "    seg_img = cv2.imread('data/prediction.png')\n",
    "    cv2.imshow(\"predictions\", seg_img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "# close the display window\n",
    "cv2.destroyAllWindows()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
